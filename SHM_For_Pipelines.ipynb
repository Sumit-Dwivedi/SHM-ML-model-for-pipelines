{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlfZ7gWpWoW4KH7N6nn0OE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumit-Dwivedi/SHM-ML-model-for-pipelines/blob/main/SHM_For_Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcuj8bRc2f11"
      },
      "outputs": [],
      "source": [
        "#SHM project\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/Merged_Pipeline_Data.xlsx\"\n",
        "xls = pd.ExcelFile(file_path, engine=\"openpyxl\")  # Ensure correct engine for .xlsx\n",
        "\n",
        "# Define the sheet names corresponding to different frequencies\n",
        "sheets = xls.sheet_names  # ['Frequency_1', 'Frequency_2', ..., 'Frequency_5']\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "for sheet in sheets:\n",
        "    print(f\"Processing {sheet}...\")\n",
        "\n",
        "    # Load the data for the current frequency\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "\n",
        "    # Ensure correct row start (skip first row if necessary)\n",
        "    if df.columns[0] != \"Distance (m)\":\n",
        "        df = pd.read_excel(xls, sheet_name=sheet, skiprows=1)\n",
        "\n",
        "    # Ensure \"Acquisition Number\" is numeric\n",
        "    df[\"Acquisition Number\"] = pd.to_numeric(df[\"Acquisition Number\"], errors=\"coerce\")\n",
        "\n",
        "    # Filter Training Data (Acquisition 22-301)\n",
        "    train_df = df[(df[\"Acquisition Number\"] >= 22) & (df[\"Acquisition Number\"] <= 301)]\n",
        "\n",
        "    # Filter Testing Data (Acquisition 302-330)\n",
        "    test_df = df[(df[\"Acquisition Number\"] >= 302) & (df[\"Acquisition Number\"] <= 330)]\n",
        "\n",
        "    # Select relevant features\n",
        "    features = [\"Torsional (V)\", \"Flexural (V)\"]\n",
        "    train_X = train_df[features].astype(float)\n",
        "    test_X = test_df[features].astype(float)\n",
        "\n",
        "    # Normalize the data\n",
        "    scaler = MinMaxScaler()\n",
        "    train_X_scaled = scaler.fit_transform(train_X)\n",
        "    test_X_scaled = scaler.transform(test_X)\n",
        "\n",
        "    ## === Autoencoder Model === ##\n",
        "    input_dim = train_X_scaled.shape[1]\n",
        "    autoencoder = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(input_dim, activation='sigmoid')\n",
        "    ])\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    autoencoder.fit(train_X_scaled, train_X_scaled, epochs=50, batch_size=16, verbose=0)\n",
        "\n",
        "    # Compute reconstruction error\n",
        "    train_pred = autoencoder.predict(train_X_scaled)\n",
        "    train_errors = np.mean(np.abs(train_X_scaled - train_pred), axis=1)\n",
        "    test_pred = autoencoder.predict(test_X_scaled)\n",
        "    test_errors = np.mean(np.abs(test_X_scaled - test_pred), axis=1)\n",
        "\n",
        "    ## === Isolation Forest === ##\n",
        "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "    iso_forest.fit(train_X_scaled)\n",
        "    test_iso_scores = iso_forest.decision_function(test_X_scaled)  # Anomaly scores\n",
        "\n",
        "    ## === One-Class SVM === ##\n",
        "    oc_svm = OneClassSVM(nu=0.05, kernel=\"rbf\", gamma=\"auto\")\n",
        "    oc_svm.fit(train_X_scaled)\n",
        "    test_svm_scores = oc_svm.decision_function(test_X_scaled)  # Anomaly scores\n",
        "\n",
        "    # Store results\n",
        "    results[sheet] = {\n",
        "        \"test_errors\": test_errors,\n",
        "        \"test_iso_scores\": test_iso_scores,\n",
        "        \"test_svm_scores\": test_svm_scores\n",
        "    }\n",
        "\n",
        "    # Plot results for the current frequency\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(test_errors, label='Autoencoder Error', color='b')\n",
        "    plt.plot(-test_iso_scores, label='Isolation Forest', color='r')\n",
        "    plt.plot(-test_svm_scores, label='One-Class SVM', color='g')\n",
        "    plt.title(f\"Anomaly Detection for {sheet}\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Combined plot across all frequencies\n",
        "plt.figure(figsize=(12, 6))\n",
        "for sheet in sheets:\n",
        "    plt.plot(results[sheet][\"test_errors\"], label=f'{sheet} (Autoencoder)')\n",
        "plt.title(\"Comparison of Autoencoder Errors Across Frequencies\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yQSZ67OhhHPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}